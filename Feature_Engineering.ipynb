{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Q1. What is a parameter?**\n",
        "\n",
        "- A parameter is a value inside a machine learning model that the algorithm learns from the training data. It defines how the model makes predictions.\n",
        "\n",
        "- For example, in linear regression, the slope and intercept are parameters that get adjusted to best fit the data.\n",
        "\n",
        "**Q2. What is correlation and what does negative correlation mean?**\n",
        "\n",
        "- Correlation shows how two variables are related to each other — whether they move in the same direction or in opposite directions. Its value ranges from –1 to +1.\n",
        "\n",
        "- A **negative correlation** means that as one variable increases, the other decreases.\n",
        "For example, as the speed of a car increases, the time taken to cover a fixed distance decreases.\n",
        "\n",
        "**Q3. Define Machine Learning. What are the main components in Machine Learning?**\n",
        "\n",
        " Machine Learning is a branch of Artificial Intelligence that allows systems to learn automatically from data and improve their performance without being explicitly programmed.\n",
        "\n",
        "The main components of Machine Learning are:\n",
        "\n",
        "1. **Data:** The raw information used for training the model.\n",
        "2. **Model:** The mathematical structure or algorithm that makes predictions or decisions.\n",
        "3. **Loss Function:** Measures how well the model is performing by calculating the error between predicted and actual values.\n",
        "4. **Optimizer:** Adjusts the model’s parameters to reduce the loss and improve accuracy.\n",
        "5. **Training Process:** The phase where the model learns patterns from the data.\n",
        "\n",
        "**Q4. How does loss value help in determining whether the model is good or not?**\n",
        "\n",
        "- The loss value tells us how far the model’s predictions are from the actual results.\n",
        "- A **low loss value** means the model is predicting more accurately and is performing well, while a **high loss value** means the model is making larger errors.\n",
        "- So, by checking the loss value during training, we can understand whether the model is learning correctly or needs improvement.\n",
        "\n",
        "**Q5. What are continuous and categorical variables?**\n",
        "\n",
        "* **Continuous variables** are numeric values that can take any value within a range. For example, height, weight, and temperature — they can be measured in decimals too.\n",
        "* **Categorical variables** represent distinct groups or categories that cannot be measured numerically. For example, gender (male/female), color (red/blue/green), or type of car (SUV/sedan).\n",
        "* In short, continuous variables deal with quantities, while categorical variables deal with qualities or labels.\n",
        "\n",
        "**Q6. How do we handle categorical variables in Machine Learning? What are the common techniques?**\n",
        "\n",
        "Machine Learning models usually require numeric input, so we need to convert categorical variables into numbers. Common techniques are:\n",
        "\n",
        "1. **Label Encoding:** Assigns a unique number to each category. For example, Red → 0, Blue → 1, Green → 2.\n",
        "2. **One-Hot Encoding:** Creates separate binary columns for each category. For example, a “Color” column becomes three columns: Red, Blue, Green, with 1 or 0 indicating presence.\n",
        "3. **Target Encoding (less common):** Replaces categories with a statistic like the mean of the target variable for that category.\n",
        "\n",
        "These techniques help models understand categorical data effectively.\n",
        "\n",
        "**Q7. What do you mean by training and testing a dataset?**\n",
        "\n",
        "In Machine Learning, we **split the dataset** into two parts:\n",
        "\n",
        "1. **Training dataset:** This is used to teach the model — the model learns patterns and relationships from this data.\n",
        "2. **Testing dataset:** This is used to evaluate the model's performance on unseen data, to check how well it generalizes.\n",
        "3. In short, training is for learning, and testing is for checking how good the learning is.\n",
        "\n",
        "**Q8. What is 'sklearn.preprocessing'?**\n",
        "\n",
        "- 'sklearn.preprocessing' is a module in the **scikit-learn** library that provides tools to **prepare and transform data** before feeding it to a machine learning model.\n",
        "\n",
        "It helps in tasks like:\n",
        "\n",
        "1. **Scaling features** - e.g., 'StandardScaler', 'MinMaxScaler' to bring all features to a similar range.\n",
        "2. **Encoding categorical data** - e.g., `OneHotEncoder', 'LabelEncoder'.\n",
        "3. **Normalizing or transforming data** - e.g., 'Normalizer', 'PolynomialFeatures'.\n",
        "\n",
        "In short, it's used to **make data suitable for training models** and improve model performance.\n",
        "\n",
        "**Q9. What is a Test set?**\n",
        "- A **test set** is a portion of the dataset that is kept separate from the training data and used to evaluate the model's performance.\n",
        "- It contains data the model hasn't seen during training, so it helps us check how well the model can make predictions on **unseen or real-world data**.\n",
        "- Test set measures the model's accuracy and generalization.\n",
        "\n",
        "**Q10. How do we split data for model fitting (training and testing) in Python? How do you approach a Machine Learning problem?**\n",
        "\n",
        "**Splitting data in Python:**\n",
        "\n",
        "We usually use **scikit-learn’s `train_test_split`** function to divide the dataset into training and testing sets. For example:\n",
        "\n",
        "```python\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "```\n",
        "\n",
        "Here, 80% of data is used for training, and 20% for testing.\n",
        "\n",
        "**Approach to a Machine Learning problem:**\n",
        "\n",
        "1. **Understand the problem** - know the goal, type of data, and expected outcome.\n",
        "2. **Collect and clean data** - handle missing values, remove duplicates, and preprocess.\n",
        "3. **Explore data** - perform exploratory data analysis (EDA) to find patterns.\n",
        "4. **Feature engineering** - select or create meaningful features.\n",
        "5. **Split data** - into training and testing sets.\n",
        "6. **Choose and train a model** - pick an appropriate algorithm and fit it to the training data.\n",
        "7. **Evaluate the model** - check performance using metrics on the test set.\n",
        "8. **Tune and improve** - optimize parameters, try different models, or adjust features.\n",
        "9. **Deploy and monitor** - use the model in real-world scenarios and update if needed.\n",
        "\n",
        "This step-by-step approach ensures a structured way to solve ML problems efficiently.\n",
        "\n",
        "**Q11. Why do we have to perform EDA before fitting a model to the data?**\n",
        "**Ans:** Exploratory Data Analysis (EDA) is performed to **understand the dataset** before training a model.\n",
        "\n",
        "It helps us:\n",
        "\n",
        "1. **Identify patterns and relationships** between features and the target variable.\n",
        "2. **Detect missing or incorrect data** that needs cleaning.\n",
        "3. **Understand the distribution of data** to choose the right model or preprocessing technique.\n",
        "4. **Spot outliers** that may affect model performance.\n",
        "\n",
        "**Q12. What is correlation?**\n",
        "\n",
        "- Correlation is a statistical measure that shows **how two variables are related** and how they move with respect to each other.\n",
        "* A **positive correlation** means that as one variable increases, the other also increases.\n",
        "* A **negative correlation** means that as one variable increases, the other decreases.\n",
        "* A correlation of **0** means there is no relationship between the variables.\n",
        "\n",
        "It helps in understanding relationships in data and in feature selection for machine learning.\n",
        "\n",
        "**Q13. What does negative correlation mean?**\n",
        "\n",
        "- Negative correlation means that **two variables move in opposite directions**.\n",
        "When one variable increases, the other decreases.\n",
        "\n",
        "For example, as the number of hours spent on exercise increases, body weight may decrease — showing a negative correlation.\n",
        "\n",
        "**Q14. How can you find correlation between variables in Python?**\n",
        "\n",
        "- In Python, correlation between variables can be found using statistical functions from libraries like **pandas** or **NumPy**.\n",
        "\n",
        "* **Pandas:** The 'corr()' function calculates the correlation matrix for all numeric columns in a dataset, showing how strongly each pair of variables is related.\n",
        "* **NumPy:** The 'corrcoef()' function can compute the correlation coefficient between two arrays.\n",
        "\n",
        "These methods give a value between –1 and +1, indicating the **strength and direction of the relationship**.\n",
        "\n",
        "**Q15. What is causation? Explain the difference between correlation and causation with an example.**\n",
        "\n",
        "**Causation** means that a change in one variable **directly causes** a change in another variable.\n",
        "\n",
        "**Difference between correlation and causation:**\n",
        "\n",
        "* **Correlation** shows a relationship or pattern between two variables, but it doesn't mean one causes the other.\n",
        "* **Causation** shows that one variable's change actually **produces a change** in the other.\n",
        "\n",
        "**Example:**\n",
        "\n",
        "* Correlation: Ice cream sales and drowning cases may both increase in summer — they are correlated, but ice cream sales don't cause drowning.\n",
        "* Causation: Smoking causes an increase in the risk of lung cancer — here, one directly affects the other.\n",
        "\n",
        "**Q16. What is an Optimizer? What are different types of optimizers? Explain each with an example.**\n",
        "\n",
        "- An **optimizer** in Machine Learning is an algorithm used to **adjust the model’s parameters** (like weights) to **minimize the loss function** and improve accuracy. In simple words, it helps the model learn efficiently.\n",
        "\n",
        "**Common types of optimizers:**\n",
        "\n",
        "1. **Gradient Descent (GD):**\n",
        "\n",
        "   * Updates all model parameters using the gradient of the loss function over the entire dataset.\n",
        "   * Example: In linear regression, gradient descent adjusts the slope and intercept to minimize mean squared error.\n",
        "\n",
        "2. **Stochastic Gradient Descent (SGD):**\n",
        "\n",
        "   * Updates parameters using **one training example at a time**, which makes it faster for large datasets but more noisy.\n",
        "   * Example: Training a neural network on millions of images — SGD updates weights after each image.\n",
        "\n",
        "3. **Mini-Batch Gradient Descent:**\n",
        "\n",
        "   * Updates parameters using a **small batch** of data (between 10-1000 samples), combining speed of SGD and stability of GD.\n",
        "   * Example: Training deep learning models on batches of 64 images.\n",
        "\n",
        "4. **Adam (Adaptive Moment Estimation):**\n",
        "\n",
        "   * Combines momentum and adaptive learning rates for each parameter, making it faster and more efficient for complex models.\n",
        "   * Example: Training CNNs for image recognition tasks like classifying cats and dogs.\n",
        "\n",
        "**Q17. What is 'sklearn.linear_model'?**\n",
        "\n",
        "- 'sklearn.linear_model' is a module in the **scikit-learn** library that provides **linear models** for regression and classification tasks.\n",
        "\n",
        "It includes algorithms like:\n",
        "\n",
        "* **Linear Regression:** Predicts a continuous target variable.\n",
        "* **Logistic Regression:** Predicts a categorical target variable (like yes/no).\n",
        "* **Ridge and Lasso Regression:** Linear models with regularization to prevent overfitting.\n",
        "\n",
        "**Q18. What does 'model.fit()' do? What arguments must be given?**\n",
        "\n",
        "The 'model.fit()' function in scikit-learn is used to **train a machine learning model** on the given data. It **learns the patterns** from the training dataset and adjusts the model's parameters accordingly.\n",
        "\n",
        "**Arguments required:**\n",
        "\n",
        "1. **X** - Input features (independent variables).\n",
        "2. **y** - Target variable (dependent variable).\n",
        "\n",
        "*Example:*\n",
        "\n",
        "```\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)  # X_train: features, y_train: target\n",
        "```\n",
        "\n",
        "After calling 'fit()', the model is ready to make predictions on new data.\n",
        "\n",
        "\n",
        "**Q19. What does 'model.predict()' do? What arguments must be given?**\n",
        "\n",
        "- The 'model.predict()' function in scikit-learn is used to **make predictions** using a trained machine learning model. After the model has learned from the training data, 'predict()' applies the learned parameters to **new or test data** to generate output.\n",
        "\n",
        "**Arguments required:**\n",
        "\n",
        "* **X** - Input features for which you want to predict the target variable.\n",
        "\n",
        "*Example:*\n",
        "\n",
        "```\n",
        "predictions = model.predict(X_test)  # X_test: new or test features\n",
        "```\n",
        "This returns the predicted values for the given input data.\n",
        "\n",
        "\n",
        "**Q20. What are continuous and categorical variables?**\n",
        "\n",
        "* **Continuous variables** are numeric and can take any value within a range, e.g., height, weight, or temperature.\n",
        "* **Categorical variables** represent distinct groups or labels, e.g., gender, color, or type of car.\n",
        "\n",
        "\n",
        "\n",
        "**Q21. What is feature scaling? How does it help in Machine Learning?**\n",
        "\n",
        "Feature scaling is the process of **bringing all features to a similar range or scale**. It helps because many ML algorithms (like gradient descent, KNN, SVM) are sensitive to the magnitude of features. Without scaling, features with larger values may dominate the learning process, leading to poor performance.\n",
        "\n",
        "\n",
        "\n",
        "**Q22. How do we perform scaling in Python?**\n",
        "\n",
        "- We can perform scaling using **scikit-learn's preprocessing module**:\n",
        "\n",
        "* **StandardScaler:** Scales features to have mean 0 and standard deviation 1.\n",
        "* **MinMaxScaler:** Scales features to a specific range, usually 0 to 1.\n",
        "\n",
        "Example:\n",
        "\n",
        "```\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)  # X: feature matrix\n",
        "```\n",
        "\n",
        "\n",
        "**Q23. What is 'sklearn.preprocessing'?**\n",
        "\n",
        "- 'sklearn.preprocessing' is a module in scikit-learn that provides **tools to preprocess and transform data** before training models.\n",
        "- It includes functions for **scaling, encoding, normalizing, and generating polynomial features**, making data suitable for machine learning.\n",
        "\n",
        "\n",
        "\n",
        "**Q24. How do we split data for model fitting (training and testing) in Python?**\n",
        "\n",
        "- We use **'train_test_split'** from scikit-learn to divide data into **training** and **testing** sets:\n",
        "\n",
        "```\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "```\n",
        "\n",
        "* **Training set:** Used to teach the model.\n",
        "* **Testing set:** Used to evaluate model performance on unseen data.\n",
        "\n",
        "\n",
        "\n",
        "**Q25. Explain data encoding.**\n",
        "\n",
        "- Data encoding is the process of **converting categorical variables into numeric format** so that ML models can understand them.\n",
        "\n",
        "Common techniques:\n",
        "\n",
        "1. **Label Encoding:** Assigns a unique number to each category.\n",
        "2. **One-Hot Encoding:** Creates separate binary columns for each category.\n",
        "3. **Target Encoding:** Replaces categories with statistics derived from the target variable.\n",
        "\n",
        "These techniques allow models to process categorical data effectively.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-0y-LO7ijTJO"
      }
    }
  ]
}